{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahap 1: Persiapan Data\n",
    "# Kumpulkan Data:\n",
    "\n",
    "# Kumpulkan data kamera yang mencakup berbagai fitur seperti harga, resolusi, ukuran sensor, berat, brand, dan lain-lain.\n",
    "# Kumpulkan juga data preferensi pengguna (jika ada) yang dapat membantu dalam proses pembobotan.\n",
    "# Preprocessing Data:\n",
    "\n",
    "# Bersihkan data dari outliers atau data yang tidak lengkap.\n",
    "# Normalisasi atau skala data jika diperlukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data awal:\n",
      "                 Nama Kamera Brand Kamera Jenis Sensor  Color Depth  \\\n",
      "0             Canon EOS 300D        Canon        APS-C         21.0   \n",
      "1              Canon EOS 10D        Canon        APS-C         21.0   \n",
      "2         Nikon Coolpix P340        Nikon       1/1.7\"         20.7   \n",
      "3         Nikon Coolpix P330        Nikon       1/1.7\"         21.0   \n",
      "4  Panasonic Lumix DMC FX150    Panasonic       1/1.7\"         18.4   \n",
      "\n",
      "   Dynamic Range  LowLight ISO      Price   Preferensi  \n",
      "0           10.8           544  5,500,000  Profesional  \n",
      "1           10.9           571  1,200,000         Hobi  \n",
      "2           11.9           273  2,838,000       Pemula  \n",
      "3           11.7           213  1,150,000       Pemula  \n",
      "4            9.6           101  3,100,000         Hobi  \n",
      "\n",
      "Kolom Price setelah konversi:\n",
      "0    5500000.0\n",
      "1    1200000.0\n",
      "2    2838000.0\n",
      "3    1150000.0\n",
      "4    3100000.0\n",
      "Name: Price, dtype: float64\n",
      "\n",
      "Data setelah konversi ke numerik:\n",
      "   Jenis Sensor  Color Depth  LowLight ISO\n",
      "0           NaN         21.0           544\n",
      "1           NaN         21.0           571\n",
      "2           NaN         20.7           273\n",
      "3           NaN         21.0           213\n",
      "4           NaN         18.4           101\n",
      "\n",
      "Data setelah menghapus NaN:\n",
      "Empty DataFrame\n",
      "Columns: [Price, Jenis Sensor, Color Depth, LowLight ISO]\n",
      "Index: []\n",
      "\n",
      "Tidak ada data yang tersisa setelah pembersihan. Silakan periksa data input Anda.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Membaca data dari CSV\n",
    "data = pd.read_csv('Data_Camera.csv')\n",
    "\n",
    "# Menampilkan beberapa baris pertama untuk verifikasi\n",
    "print(\"Data awal:\")\n",
    "print(data.head())\n",
    "\n",
    "# Menghapus tanda pemisah ribuan dan mengubah tipe data menjadi float\n",
    "data['Price'] = data['Price'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Menampilkan kolom Price untuk verifikasi\n",
    "print(\"\\nKolom Price setelah konversi:\")\n",
    "print(data['Price'].head())\n",
    "\n",
    "# Pastikan kolom lain yang diperlukan juga dalam format numerik\n",
    "data['Jenis Sensor'] = pd.to_numeric(data['Jenis Sensor'], errors='coerce')\n",
    "data['Color Depth'] = pd.to_numeric(data['Color Depth'], errors='coerce')\n",
    "data['LowLight ISO'] = pd.to_numeric(data['LowLight ISO'], errors='coerce')\n",
    "\n",
    "# Menampilkan data setelah konversi untuk verifikasi\n",
    "print(\"\\nData setelah konversi ke numerik:\")\n",
    "print(data[['Jenis Sensor', 'Color Depth', 'LowLight ISO']].head())\n",
    "\n",
    "# Menghapus baris yang memiliki nilai NaN (jika ada)\n",
    "data.dropna(subset=['Price', 'Jenis Sensor', 'Color Depth', 'LowLight ISO'], inplace=True)\n",
    "\n",
    "# Menampilkan data setelah menghapus baris dengan nilai NaN\n",
    "print(\"\\nData setelah menghapus NaN:\")\n",
    "print(data[['Price', 'Jenis Sensor', 'Color Depth', 'LowLight ISO']].head())\n",
    "\n",
    "# Memastikan bahwa ada data yang tersisa untuk dinormalisasi\n",
    "if not data.empty:\n",
    "    # Normalisasi data\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data[['Price', 'Jenis Sensor', 'Color Depth', 'LowLight ISO']])\n",
    "\n",
    "    # Memasukkan kembali data yang telah dinormalisasi ke dalam DataFrame\n",
    "    data[['Price', 'Jenis Sensor', 'Color Depth', 'LowLight ISO']] = data_scaled\n",
    "\n",
    "    # Menampilkan data untuk memverifikasi hasil\n",
    "    print(\"\\nData setelah normalisasi:\")\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"\\nTidak ada data yang tersisa setelah pembersihan. Silakan periksa data input Anda.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahap 2: Tentukan Kriteria dan Subkriteria\n",
    "# 1. Identifikasi Kriteria Utama\n",
    "    # Kriteria utama adalah faktor-faktor utama yang mempengaruhi keputusan pembelian kamera. Misalnya, beberapa kriteria utama bisa meliputi:\n",
    "\n",
    "    # Harga\n",
    "    # Jenis Sensor\n",
    "    # Resolusi\n",
    "    # Kedalaman Warna\n",
    "    # ISO Rendah\n",
    "# 2. Tentukan Subkriteria (jika diperlukan)\n",
    "    # Subkriteria adalah rincian lebih lanjut dari kriteria utama. Tidak semua kriteria memerlukan subkriteria, tetapi untuk beberapa faktor yang lebih kompleks, subkriteria dapat membantu memperjelas keputusan. Misalnya:\n",
    "\n",
    "    # Harga:\n",
    "    # Harga di bawah $500\n",
    "    # Harga antara $500 - $1000\n",
    "    # Harga di atas $1000\n",
    "    # Jenis Sensor:\n",
    "    # APS-C\n",
    "    # Full Frame\n",
    "    # Medium Format\n",
    "# 3. Struktur Hierarki\n",
    "    # Struktur hierarki menunjukkan bagaimana kriteria dan subkriteria diorganisir. Berikut adalah contoh struktur hierarki untuk keputusan pembelian kamera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                       Tujuan\n",
    "#                         |\n",
    "#            ---------------------------\n",
    "#            |           |             |\n",
    "#          Harga      Jenis Sensor   Resolusi   ... (dan seterusnya)\n",
    "#            |           |             |\n",
    "#   -----------       --------       --------\n",
    "#   |    |    |       |      |       |      |\n",
    "#  < $500  $500-$1000 > $1000 APS-C Full Frame ... (dan seterusnya)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementasi dengan Python\n",
    "# Untuk menerapkan metode F-AHP dalam Python, kita perlu membangun matriks perbandingan \n",
    "# berpasangan untuk setiap level dalam hierarki. \n",
    "# Di sini, kita menggunakan library seperti numpy untuk menangani perhitungan matriks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bobot Kriteria Utama: {'Price': 0.5128128127814086, 'Jenis Sensor': 0.2614990557217761, 'Color Depth': 0.12897642312026958, 'Dynamic Range': 0.06337652767438601, 'LowLight ISO': 0.033335180702159815}\n",
      "Bobot Subkriteria Harga: {'< 500.000': 0.5396145502210747, '500.000-1.000.000': 0.29696133121249724, '> 1.000.000': 0.16342411856642797}\n"
     ]
    }
   ],
   "source": [
    "# Tentukan kriteria utama\n",
    "kriteria = ['Price', 'Jenis Sensor', 'Color Depth', 'Dynamic Range', 'LowLight ISO']\n",
    "\n",
    "# Matriks perbandingan berpasangan untuk kriteria utama\n",
    "# Contoh skala perbandingan berpasangan (misal, 1 = sama penting, 3 = cukup lebih penting, 5 = sangat lebih penting, dst.)\n",
    "# Anggap kita sudah menentukan perbandingan kriteria ini sebelumnya\n",
    "pairwise_matrix = np.array([\n",
    "    [1, 3, 5, 7, 9],\n",
    "    [1/3, 1, 3, 5, 7],\n",
    "    [1/5, 1/3, 1, 3, 5],\n",
    "    [1/7, 1/5, 1/3, 1, 3],\n",
    "    [1/9, 1/7, 1/5, 1/3, 1]\n",
    "])\n",
    "\n",
    "# Fungsi untuk menghitung bobot dari matriks perbandingan berpasangan\n",
    "def calculate_weights(matrix):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(matrix)\n",
    "    max_eigenvalue = np.max(eigenvalues)\n",
    "    max_eigenvector = eigenvectors[:, np.argmax(eigenvalues)].real\n",
    "    weights = max_eigenvector / np.sum(max_eigenvector)\n",
    "    return weights\n",
    "\n",
    "# Hitung bobot kriteria utama\n",
    "kriteria_weights = calculate_weights(pairwise_matrix)\n",
    "print(\"Bobot Kriteria Utama:\", dict(zip(kriteria, kriteria_weights)))\n",
    "\n",
    "# Jika kita memiliki subkriteria, kita juga perlu membuat matriks perbandingan berpasangan untuk subkriteria setiap kriteria.\n",
    "# Misalnya untuk subkriteria Harga:\n",
    "subkriteria_harga = ['< 500.000', '500.000-1.000.000', '> 1.000.000']\n",
    "pairwise_matrix_harga = np.array([\n",
    "    [1, 2, 3],\n",
    "    [1/2, 1, 2],\n",
    "    [1/3, 1/2, 1]\n",
    "])\n",
    "\n",
    "# Hitung bobot subkriteria Harga\n",
    "subkriteria_harga_weights = calculate_weights(pairwise_matrix_harga)\n",
    "print(\"Bobot Subkriteria Harga:\", dict(zip(subkriteria_harga, subkriteria_harga_weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahap 3: Fuzzy AHP\n",
    "    # Langkah-langkah Fuzzy AHP\n",
    "    # Definisikan Skala Fuzzy:\n",
    "\n",
    "    # Tentukan skala perbandingan fuzzy menggunakan bilangan fuzzy segitiga (Triangular Fuzzy Numbers - TFN).\n",
    "    # Buat Matriks Perbandingan Fuzzy:\n",
    "\n",
    "    # Bangun matriks perbandingan berpasangan dengan nilai fuzzy.\n",
    "    # Hitung Sintesis Fuzzy:\n",
    "\n",
    "    # Hitung bobot prioritas fuzzy untuk setiap kriteria dan subkriteria.\n",
    "    # Defuzzifikasi:\n",
    "\n",
    "    # Konversi bilangan fuzzy menjadi nilai tunggal (crisp) untuk mendapatkan bobot akhir.\n",
    "# Langkah 1: Definisikan Skala Fuzzy\n",
    "    # Berikut adalah contoh skala fuzzy dengan bilangan fuzzy segitiga:\n",
    "\n",
    "    # 1: (1, 1, 1)\n",
    "    # 3: (2, 3, 4)\n",
    "    # 5: (4, 5, 6)\n",
    "    # 7: (6, 7, 8)\n",
    "    # 9: (8, 9, 10)\n",
    "# Langkah 2: Buat Matriks Perbandingan Fuzzy\n",
    "# Bangun matriks perbandingan berpasangan untuk kriteria dan subkriteria menggunakan skala fuzzy yang telah ditentukan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisikan bilangan fuzzy segitiga\n",
    "fuzzy_scale = {\n",
    "    1: (1, 1, 1),\n",
    "    3: (2, 3, 4),\n",
    "    5: (4, 5, 6),\n",
    "    7: (6, 7, 8),\n",
    "    9: (8, 9, 10)\n",
    "}\n",
    "\n",
    "# Matriks perbandingan berpasangan fuzzy (contoh)\n",
    "fuzzy_pairwise_matrix = [\n",
    "    [(1, 1, 1), (2, 3, 4), (4, 5, 6)],\n",
    "    [(1/4, 1/3, 1/2), (1, 1, 1), (2, 3, 4)],\n",
    "    [(1/6, 1/5, 1/4), (1/4, 1/3, 1/2), (1, 1, 1)]\n",
    "]\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "fuzzy_pairwise_matrix = np.array(fuzzy_pairwise_matrix, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langkah 3: Hitung Sintesis Fuzzy\n",
    "# Untuk menghitung bobot prioritas fuzzy, kita perlu melakukan operasi fuzzy pada matriks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crisp Weights:\n",
      "[0.6439333175373473, 0.31366352794573205, 0.11025486140972351]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "# Definisikan bilangan fuzzy segitiga\n",
    "fuzzy_scale = {\n",
    "    1: (1, 1, 1),\n",
    "    3: (2, 3, 4),\n",
    "    5: (4, 5, 6),\n",
    "    7: (6, 7, 8),\n",
    "    9: (8, 9, 10)\n",
    "}\n",
    "\n",
    "# Matriks perbandingan berpasangan fuzzy (contoh)\n",
    "fuzzy_pairwise_matrix = [\n",
    "    [(1, 1, 1), (2, 3, 4), (4, 5, 6)],\n",
    "    [(1/4, 1/3, 1/2), (1, 1, 1), (2, 3, 4)],\n",
    "    [(1/6, 1/5, 1/4), (1/4, 1/3, 1/2), (1, 1, 1)]\n",
    "]\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "fuzzy_pairwise_matrix = np.array(fuzzy_pairwise_matrix, dtype=object)\n",
    "\n",
    "# Function to perform fuzzy multiplication\n",
    "def fuzzy_multiply(a, b):\n",
    "    return (a[0] * b[0], a[1] * b[1], a[2] * b[2])\n",
    "\n",
    "# Function to perform fuzzy addition\n",
    "def fuzzy_add(a, b):\n",
    "    return (a[0] + b[0], a[1] + b[1], a[2] + b[2])\n",
    "\n",
    "# Compute fuzzy sum for each row\n",
    "fuzzy_sums = [reduce(fuzzy_add, row) for row in fuzzy_pairwise_matrix]\n",
    "\n",
    "# Normalize the fuzzy sums\n",
    "total_sum = reduce(fuzzy_add, fuzzy_sums)\n",
    "\n",
    "# Normalize each fuzzy sum\n",
    "def normalize_fuzzy(sums, total_sum):\n",
    "    return (sums[0] / total_sum[2], sums[1] / total_sum[1], sums[2] / total_sum[0])\n",
    "\n",
    "fuzzy_extent = [normalize_fuzzy(sums, total_sum) for sums in fuzzy_sums]\n",
    "\n",
    "# Langkah 4: Defuzzifikasi\n",
    "# Defuzzifikasi mengubah bilangan fuzzy menjadi nilai crisp. Salah satu metode defuzzifikasi adalah metode centroid.\n",
    "\n",
    "# Defuzzify fuzzy weights using centroid method\n",
    "def defuzzify(triangular_fuzzy_number):\n",
    "    l, m, u = triangular_fuzzy_number\n",
    "    return (l + m + u) / 3\n",
    "\n",
    "# Defuzzify fuzzy weights\n",
    "crisp_weights = [defuzzify(weight) for weight in fuzzy_extent]\n",
    "\n",
    "print(\"Crisp Weights:\")\n",
    "print(crisp_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penjelasan\n",
    "# Definisikan Skala Fuzzy:\n",
    "\n",
    "# Menggunakan bilangan fuzzy segitiga untuk mewakili perbandingan kriteria.\n",
    "# Buat Matriks Perbandingan Fuzzy:\n",
    "\n",
    "# Bangun matriks perbandingan berpasangan dengan nilai fuzzy.\n",
    "# Hitung Sintesis Fuzzy:\n",
    "\n",
    "# Menggunakan operasi fuzzy untuk menghitung bobot prioritas fuzzy.\n",
    "# Defuzzifikasi:\n",
    "\n",
    "# Mengonversi bobot fuzzy menjadi nilai crisp untuk mendapatkan bobot akhir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahap 4: Integrasi dengan Machine Learning\n",
    "# Latih Model Machine Learning:\n",
    "# Gunakan model machine learning untuk memprediksi preferensi pengguna atau menyarankan kamera berdasarkan kriteria yang telah dihitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset kosong.\n",
      "Nilai kosong dalam kolom:\n",
      "Price           0.0\n",
      "Jenis Sensor    0.0\n",
      "Color Depth     0.0\n",
      "LowLight ISO    0.0\n",
      "Preferensi      0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [Nama Kamera, Brand Kamera, Jenis Sensor, Color Depth, Dynamic Range, LowLight ISO, Price, Preferensi]\n",
      "Index: []\n",
      "Data tidak cocok untuk dibagi dan dilatih.\n"
     ]
    }
   ],
   "source": [
    "# Periksa apakah data kosong\n",
    "if data.empty:\n",
    "    print(\"Dataset kosong.\")\n",
    "\n",
    "# Periksa apakah kolom yang diperlukan ada\n",
    "required_columns = ['Price', 'Jenis Sensor', 'Color Depth', 'LowLight ISO', 'Preferensi']\n",
    "missing_columns = [col for col in required_columns if col not in data.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Kolom yang hilang: {missing_columns}\")\n",
    "\n",
    "# Periksa nilai kosong\n",
    "null_values = data[required_columns].isnull().sum()\n",
    "print(f\"Nilai kosong dalam kolom:\\n{null_values}\")\n",
    "\n",
    "# Periksa beberapa baris pertama dari DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Lanjutkan dengan train_test_split jika semua pemeriksaan lolos\n",
    "if not data.empty and not missing_columns and null_values.sum() == 0:\n",
    "    X = data[['Price', 'Jenis Sensor', 'Color Depth', 'LowLight ISO']]\n",
    "    y = data['Preferensi']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    # Latih model\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "else:\n",
    "    print(\"Data tidak cocok untuk dibagi dan dilatih.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJenis Sensor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColor Depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLowLight ISO\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreferensi\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Kolom preferensi harus ada dalam data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n",
      "File \u001b[1;32mc:\\Users\\Laptop\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Laptop\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Laptop\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2277\u001b[0m     )\n\u001b[0;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data\n",
    "X = data[['Price', 'Jenis Sensor', 'Color Depth', 'LowLight ISO']]\n",
    "y = data['Preferensi']  # Kolom preferensi harus ada dalam data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
